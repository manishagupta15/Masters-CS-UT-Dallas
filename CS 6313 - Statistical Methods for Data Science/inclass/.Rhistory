# mean of x mean of y
# 46.79474  10.15357
# Note: we can set the var.equal flag to TRUE to get the interval using
# equal variance assumption (to use pooled sample variance)
t.test(x,y, alternative = "two.sided", var.equal = T,conf.level = 0.95)
###########
# Example 2 #
###########
p1.hat <- 610/4140
p2.hat <- 740/5010
n1 <- 414000000
n2 <- 501000000
alpha <- 0.05
diff.ci <- p1.hat-p2.hat + c(-1, 1)*qnorm(1-alpha/2)*
sqrt((p1.hat*(1-p1.hat)/n1)+(p2.hat*(1-p2.hat)/n2))
# > diff.ci
# [1] -0.04652425  0.04580106
# >
###########
# Example 3 #
###########
bp <- read.table("bp.txt", header = T, sep = "\t")
# > head(bp)
# armsys fingsys
# 1    140     154
# 2    110     112
# 3    138     156
# 4    124     152
# 5    142     142
# 6    112     104
# >
# boxplots
boxplot(bp)
# histograms and QQ plots
par(mfrow = c(1, 2))
hist(bp[,1])
qqnorm(bp[,1])
qqline(bp[,1])
hist(bp[,2])
qqnorm(bp[,2])
qqline(bp[,2])
# histogram and QQ plot of differences
diff <- bp[,1] - bp[,2]
boxplot(diff)
hist(diff)
qqnorm(diff)
qqline(diff)
# confidence interval
t.test(diff, alternative = "two.sided")
# > t.test(diff, alternative = "two.sided")
# One Sample t-test
# data:  diff
# t = -4.1642, df = 199, p-value = 4.652e-05
# alternative hypothesis: true mean is not equal to 0
# 95 percent confidence interval:
# -6.328898 -2.261102
# sample estimates:
# mean of x
# -4.295
# >
# directly using formula
n <- length(diff)
mean(diff) + c(-1, 1)* qt(0.975, n-1) * sd(diff)/sqrt(n)
# > mean(diff) + c(-1, 1)* qt(0.975, n-1) * sd(diff)/sqrt(n)
# [1] -6.328898 -2.261102
# >
#################################
#####################################################################################
# Making a map using R #
# Making a map esesntially involves three steps --- getting a shape file for map,
#		getting the data, and plotting. As an example, we will make a map of
#		state level income share of the top 1% of income earners in 2012 in
#		the US (see http://www.shsu.edu/eco_mwf/inequality.html for more
#		more information about the variable and the data.)
#		But the ideas are quite general.
# Much of what you would see below has been learnt from:
# (a) http://www.kevjohnson.org/making-maps-in-r/ for a general introduction to map
#		making in R
# (b) https://www.nceas.ucsb.edu/~frazier/RSpatialGuides/colorPaletteCheatsheet.pdf
#		for an introduction to colors in R
# See also:
# https://www.nceas.ucsb.edu/~frazier/RSpatialGuides/ggmap/ggmapCheatsheet.pdf
#		for an introduction to using Google maps in making maps using
#		using the R package ggmap
#####################################################################################
# Use ?functionname to see help on any unfamiliar functions.
# If not already installed, use install.packages("packagename") to first install
# a package before loading it with library command.
library(raster) # to get map shape file
library(ggplot2) # for plotting and miscellaneuous things
library(ggmap) # for plotting
library(plyr) # for merging datasets
library(scales) # to get nice looking legends
library(maps)
# Get a shape file of states in the US
usa.df <- map_data("state")
colnames(usa.df)[5] <- "State"
# Get the data to be plotted
usa.dat <- read.table("usstatesWTID.csv", header = T, sep = ",")
usa.dat$State <- tolower(usa.dat$State)
usa.dat <- usa.dat[usa.dat$Year == 2012, c("Year", "State", "Top1_adj")]
# Merge the data with the shape file
usa.df <- join(usa.df, usa.dat, by = "State", type = "inner")
# Abbreviations of states and where thy should be plotted
states <- data.frame(state.center, state.abb) # centers of states and abbreviations
subset <- tolower(state.name) %in% usa.df$State # exclude Hawaii as there is no data for this state
states <- states[subset, ]
# Write a function that does the plotting (Feel free to play around
# with the options)
p <- function(data, brks, title) {
ggp <- ggplot() +
#		Draw borders of states
geom_polygon(data = data, aes(x = long, y = lat, group = group,
fill = Top1_adj), color = "black", size = 0.15) +
# 		Use shades of red for plotting; trans = "reverse" option
# 		makes the shades go from dark to light as the income share increases,
#		ensuring that darkest red = worst case scenario.
scale_fill_distiller(palette = "Reds", breaks = brks,
trans = "reverse") +
#		Add legend
theme_nothing(legend = TRUE) + labs(title = title, fill = "") +
#		Add state abbreviations
geom_text(data = states, aes(x = x, y = y, label = state.abb), size = 3)
return(ggp)
}
# Get the break points for different shades
# > range(usa.df$Top1_adj)
# [1] 13.68477 33.00785
# >
brks.to.use <- seq(10, 34, by = 4) # give intervals:
# 10-14 (less than 14), 14-18, ..., 30-34 (>= 30)
figure.title <- "Income share of top 1% earners in 2012"
# Save the map to a file to viewing (you can plot on the screen also, but it takes
# much longer that way. The ratio of US height to width is 1:9.)
ggsave(p(usa.df, brks.to.use, figure.title), height = 4, width = 4*1.9,
file = "usa_income_share.jpg")
#####################################################################################
# Making a map using R #
# Making a map esesntially involves three steps --- getting a shape file for map,
#		getting the data, and plotting. As an example, we will make a map of
#		state level income share of the top 1% of income earners in 2012 in
#		the US (see http://www.shsu.edu/eco_mwf/inequality.html for more
#		more information about the variable and the data.)
#		But the ideas are quite general.
# Much of what you would see below has been learnt from:
# (a) http://www.kevjohnson.org/making-maps-in-r/ for a general introduction to map
#		making in R
# (b) https://www.nceas.ucsb.edu/~frazier/RSpatialGuides/colorPaletteCheatsheet.pdf
#		for an introduction to colors in R
# See also:
# https://www.nceas.ucsb.edu/~frazier/RSpatialGuides/ggmap/ggmapCheatsheet.pdf
#		for an introduction to using Google maps in making maps using
#		using the R package ggmap
#####################################################################################
# Use ?functionname to see help on any unfamiliar functions.
# If not already installed, use install.packages("packagename") to first install
# a package before loading it with library command.
library(raster) # to get map shape file
library(ggplot2) # for plotting and miscellaneuous things
library(ggmap) # for plotting
library(plyr) # for merging datasets
library(scales) # to get nice looking legends
library(maps)
# Get a shape file of states in the US
usa.df <- map_data("state")
colnames(usa.df)[5] <- "State"
# Get the data to be plotted
usa.dat <- read.table("usstatesWTID.csv", header = T, sep = ",")
usa.dat$State <- tolower(usa.dat$State)
usa.dat <- usa.dat[usa.dat$Year == 2012, c("Year", "State", "Top1_adj")]
# Merge the data with the shape file
usa.df <- join(usa.df, usa.dat, by = "State", type = "inner")
# Abbreviations of states and where thy should be plotted
states <- data.frame(state.center, state.abb) # centers of states and abbreviations
subset <- tolower(state.name) %in% usa.df$State # exclude Hawaii as there is no data for this state
states <- states[subset, ]
# Write a function that does the plotting (Feel free to play around
# with the options)
p <- function(data, brks, title) {
ggp <- ggplot() +
#		Draw borders of states
geom_polygon(data = data, aes(x = long, y = lat, group = group,
fill = Top1_adj), color = "black", size = 0.15) +
# 		Use shades of red for plotting; trans = "reverse" option
# 		makes the shades go from dark to light as the income share increases,
#		ensuring that darkest red = worst case scenario.
scale_fill_distiller(palette = "Reds", breaks = brks,
trans = "reverse") +
#		Add legend
theme_nothing(legend = TRUE) + labs(title = title, fill = "") +
#		Add state abbreviations
geom_text(data = states, aes(x = x, y = y, label = state.abb), size = 3)
return(ggp)
}
# Get the break points for different shades
# > range(usa.df$Top1_adj)
# [1] 13.68477 33.00785
# >
brks.to.use <- seq(10, 34, by = 4) # give intervals:
# 10-14 (less than 14), 14-18, ..., 30-34 (>= 30)
figure.title <- "Income share of top 1% earners in 2012"
# Save the map to a file to viewing (you can plot on the screen also, but it takes
# much longer that way. The ratio of US height to width is 1:9.)
ggsave(p(usa.df, brks.to.use, figure.title), height = 4, width = 4*1.9,
file = "usa_income_share.jpg")
install.packages(raster)
install.packages('raster')
install.packages('ggplot2')
# Read the house price data
house <- read.table(file="house_price.txt", sep=",", header=T)
> head(house)
size price
1 0.951 30.00
2 1.036 39.90
3 0.676 46.50
4 1.456 48.60
5 1.186 51.50
6 1.456 56.99
>
> str(house)
'data.frame':	58 obs. of  2 variables:
$ size : num  0.951 1.036 0.676 1.456 1.186 ...
$ price: num  30 39.9 46.5 48.6 51.5 ...
>
# Make a scatterplot
x <- house$size
y <- house$price
plot(x, y, xlab="square footage (1000 sq feet)", ylab="price ($1000)")
# Correlation
> cor(x,y)
[1] 0.8759374
>
# Get the fitted regression line
> (house.reg <- lm (y ~ x))
Call:
lm(formula = y ~ x)
Coefficients:
(Intercept)            x
5.432       56.083
>
# Does R do what we expect it to do?
> c(mean(x), sd(x), mean(y), sd(y), cor(x,y))
[1]   1.8829655   0.6316624 111.0344483  40.4431900   0.8759374
>
> cor(x,y)*sd(y)/sd(x)
[1] 56.08328
>
> mean(y)-(cor(x,y)*sd(y)/sd(x))*mean(x)
[1] 5.431568
>
# Add the line to the plot
plot(x, y, xlab="square footage (1000 sq feet)", ylab="price ($1000)")
abline(house.reg)
x <- house$size
y <- house$price
house.reg <- lm (y ~ x)
# ANOVA table
> (anova(house.reg))
Analysis of Variance Table
Response: y
Df Sum Sq Mean Sq F value    Pr(>F)
x          1  71534   71534  184.62 < 2.2e-16 ***
Residuals 56  21698     387
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
>
# Testing for zero slope
> summary(house.reg)
Call:
lm(formula = y ~ x)
Residuals:
Min      1Q  Median      3Q     Max
-38.489 -14.512  -1.422  14.919  54.389
Coefficients:
Estimate Std. Error t value Pr(>|t|)
(Intercept)    5.432      8.191   0.663     0.51
x             56.083      4.128  13.587   <2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
Residual standard error: 19.68 on 56 degrees of freedom
Multiple R-squared: 0.7673,	Adjusted R-squared: 0.7631
F-statistic: 184.6 on 1 and 56 DF,  p-value: < 2.2e-16
>
# Confidence interval for slope
> confint(house.reg)
2.5 %   97.5 %
(Intercept) -10.97619 21.83933
x            47.81473 64.35183
>
# Prediction at a new x
x.new <- data.frame(x=3)
> (predict(house.reg, newdata=x.new))
1
173.6814
>
# Use fitted(house.reg) to get the fitted values
# Use resid(house.reg) to get the residuals
# Residual plot
plot(fitted(house.reg), resid(house.reg))
abline(h=0)
# QQ plot
qqnorm(resid(house.reg))
qqline(resid(house.reg))
# Time series plot of residuals
plot(resid(house.reg), type="l")
abline(h=0)
house <- read.table(file="house_price.txt", sep=",", header=T)
install.packages("ggmap")
install.packages("plyr")
#####################################################################################
# Making a map using R #
# Making a map esesntially involves three steps --- getting a shape file for map,
#		getting the data, and plotting. As an example, we will make a map of
#		state level income share of the top 1% of income earners in 2012 in
#		the US (see http://www.shsu.edu/eco_mwf/inequality.html for more
#		more information about the variable and the data.)
#		But the ideas are quite general.
# Much of what you would see below has been learnt from:
# (a) http://www.kevjohnson.org/making-maps-in-r/ for a general introduction to map
#		making in R
# (b) https://www.nceas.ucsb.edu/~frazier/RSpatialGuides/colorPaletteCheatsheet.pdf
#		for an introduction to colors in R
# See also:
# https://www.nceas.ucsb.edu/~frazier/RSpatialGuides/ggmap/ggmapCheatsheet.pdf
#		for an introduction to using Google maps in making maps using
#		using the R package ggmap
#####################################################################################
# Use ?functionname to see help on any unfamiliar functions.
# If not already installed, use install.packages("packagename") to first install
# a package before loading it with library command.
library(raster) # to get map shape file
library(ggplot2) # for plotting and miscellaneuous things
library(ggmap) # for plotting
library(plyr) # for merging datasets
library(scales) # to get nice looking legends
library(maps)
# Get a shape file of states in the US
usa.df <- map_data("state")
colnames(usa.df)[5] <- "State"
# Get the data to be plotted
usa.dat <- read.table("usstatesWTID.csv", header = T, sep = ",")
usa.dat$State <- tolower(usa.dat$State)
usa.dat <- usa.dat[usa.dat$Year == 2012, c("Year", "State", "Top1_adj")]
# Merge the data with the shape file
usa.df <- join(usa.df, usa.dat, by = "State", type = "inner")
# Abbreviations of states and where thy should be plotted
states <- data.frame(state.center, state.abb) # centers of states and abbreviations
subset <- tolower(state.name) %in% usa.df$State # exclude Hawaii as there is no data for this state
states <- states[subset, ]
# Write a function that does the plotting (Feel free to play around
# with the options)
p <- function(data, brks, title) {
ggp <- ggplot() +
#		Draw borders of states
geom_polygon(data = data, aes(x = long, y = lat, group = group,
fill = Top1_adj), color = "black", size = 0.15) +
# 		Use shades of red for plotting; trans = "reverse" option
# 		makes the shades go from dark to light as the income share increases,
#		ensuring that darkest red = worst case scenario.
scale_fill_distiller(palette = "Reds", breaks = brks,
trans = "reverse") +
#		Add legend
theme_nothing(legend = TRUE) + labs(title = title, fill = "") +
#		Add state abbreviations
geom_text(data = states, aes(x = x, y = y, label = state.abb), size = 3)
return(ggp)
}
# Get the break points for different shades
# > range(usa.df$Top1_adj)
# [1] 13.68477 33.00785
# >
brks.to.use <- seq(10, 34, by = 4) # give intervals:
# 10-14 (less than 14), 14-18, ..., 30-34 (>= 30)
figure.title <- "Income share of top 1% earners in 2012"
# Save the map to a file to viewing (you can plot on the screen also, but it takes
# much longer that way. The ratio of US height to width is 1:9.)
ggsave(p(usa.df, brks.to.use, figure.title), height = 4, width = 4*1.9,
file = "usa_income_share.jpg")
install.packages("plyr")
install.packages("maps")
install.packages("scales")
install.packages("scales")
#####################################################################################
# Making a map using R #
# Making a map esesntially involves three steps --- getting a shape file for map,
#		getting the data, and plotting. As an example, we will make a map of
#		state level income share of the top 1% of income earners in 2012 in
#		the US (see http://www.shsu.edu/eco_mwf/inequality.html for more
#		more information about the variable and the data.)
#		But the ideas are quite general.
# Much of what you would see below has been learnt from:
# (a) http://www.kevjohnson.org/making-maps-in-r/ for a general introduction to map
#		making in R
# (b) https://www.nceas.ucsb.edu/~frazier/RSpatialGuides/colorPaletteCheatsheet.pdf
#		for an introduction to colors in R
# See also:
# https://www.nceas.ucsb.edu/~frazier/RSpatialGuides/ggmap/ggmapCheatsheet.pdf
#		for an introduction to using Google maps in making maps using
#		using the R package ggmap
#####################################################################################
# Use ?functionname to see help on any unfamiliar functions.
# If not already installed, use install.packages("packagename") to first install
# a package before loading it with library command.
library(raster) # to get map shape file
library(ggplot2) # for plotting and miscellaneuous things
library(ggmap) # for plotting
library(plyr) # for merging datasets
library(scales) # to get nice looking legends
library(maps)
# Get a shape file of states in the US
usa.df <- map_data("state")
colnames(usa.df)[5] <- "State"
# Get the data to be plotted
usa.dat <- read.table("usstatesWTID.csv", header = T, sep = ",")
usa.dat$State <- tolower(usa.dat$State)
usa.dat <- usa.dat[usa.dat$Year == 2012, c("Year", "State", "Top1_adj")]
# Merge the data with the shape file
usa.df <- join(usa.df, usa.dat, by = "State", type = "inner")
# Abbreviations of states and where thy should be plotted
states <- data.frame(state.center, state.abb) # centers of states and abbreviations
subset <- tolower(state.name) %in% usa.df$State # exclude Hawaii as there is no data for this state
states <- states[subset, ]
# Write a function that does the plotting (Feel free to play around
# with the options)
p <- function(data, brks, title) {
ggp <- ggplot() +
#		Draw borders of states
geom_polygon(data = data, aes(x = long, y = lat, group = group,
fill = Top1_adj), color = "black", size = 0.15) +
# 		Use shades of red for plotting; trans = "reverse" option
# 		makes the shades go from dark to light as the income share increases,
#		ensuring that darkest red = worst case scenario.
scale_fill_distiller(palette = "Reds", breaks = brks,
trans = "reverse") +
#		Add legend
theme_nothing(legend = TRUE) + labs(title = title, fill = "") +
#		Add state abbreviations
geom_text(data = states, aes(x = x, y = y, label = state.abb), size = 3)
return(ggp)
}
# Get the break points for different shades
# > range(usa.df$Top1_adj)
# [1] 13.68477 33.00785
# >
brks.to.use <- seq(10, 34, by = 4) # give intervals:
# 10-14 (less than 14), 14-18, ..., 30-34 (>= 30)
figure.title <- "Income share of top 1% earners in 2012"
# Save the map to a file to viewing (you can plot on the screen also, but it takes
# much longer that way. The ratio of US height to width is 1:9.)
ggsave(p(usa.df, brks.to.use, figure.title), height = 4, width = 4*1.9,
file = "usa_income_share.jpg")
usa.df <- map_data("state")
colnames(usa.df)[5] <- "State"
usa.dat <- read.table("usstatesWTID.csv", header = T, sep = ",")
usa.dat$State <- tolower(usa.dat$State)
usa.dat <- usa.dat[usa.dat$Year == 2012, c("Year", "State", "Top1_adj")]
usa.dat <- read.table("usstatesWTID.csv", header = T, sep = ",")
# Time between keystrokes data from Example 10.9
x <- c(0.24, 0.22, 0.26, 0.34, 0.35, 0.32, 0.33, 0.29, 0.19, 0.36,
0.30, 0.15, 0.17, 0.28, 0.38, 0.40, 0.37,0.27)
# Histogram and boxplot
par(mfrow=c(1,2)) # 2 plots in 1 row
hist(x)
qqnorm(x)
qqline(x)
library(nortest)
> shapiro.test(x)
Shapiro-Wilk normality test
data:  x
W = 0.9611, p-value = 0.6233
>
# Sign test of H0: M = 0.2 vs M is not equal to 0.2
sign.stat <- sum(x > 0.2)
> sign.stat
[1] 15
>
> binom.test(sign.stat, n=sum(x != 0.2), p = 0.5, alt="two.sided", conf.level=0.95)
Exact binomial test
data:  sign.stat and sum(x != 0.2)
number of successes = 15, number of trials =
18, p-value = 0.007538
alternative hypothesis: true probability of success is not equal to 0.5
95 percent confidence interval:
0.5858225 0.9642149
sample estimates:
probability of success
0.8333333
>
wilcox.test(x,alternative = "two.sided",
mu = 0.2, conf.level = 0.95)
>   wilcox.test(x,alternative = "two.sided",
+               mu = 0.2, conf.level = 0.95)
Wilcoxon signed rank test
data:  x
V = 162, p-value = 0.0002518
alternative hypothesis: true location is not equal to 0.2
>
# Example 10.12 on page 319
# Wilcoxon signed rank test H0: M = 0.2 vs M is not equal to 0.2
x <- c(7, 5.5, 9.5, 6, 3.5, 9)
> wilcox.test(x,alternative = "greater",
mu = 5, conf.level = 0.95)
Wilcoxon signed rank test
data:  x
V = 18, p-value = 0.07813
alternative hypothesis: true location is greater than 5
>
# Exercise 10.22 on page 325
x <- c(0.4, 2.1, 3.6, 0.6, 0.8, 2.4, 4.0)
y <- c(1.2, 0.2, 0.3, 3.3, 2.0, 0.9, 1.1, 1.5)
wilcox.test(x, y, alternative="two.sided")
shapiro.test(x)
